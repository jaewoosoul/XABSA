# XABSA: Cross-lingual Aspect-Based Sentiment Analysis

LLM Teacher ê¸°ë°˜ Cross-lingual ABSA ì‹œìŠ¤í…œ. ì˜ì–´/í•œêµ­ì–´ ë¦¬ë·°ì—ì„œ aspect-based sentiment triplet (term, category, polarity)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

## ì£¼ìš” íŠ¹ì§•

- **LLM Teacher**: GPT-4/Claude/Geminië¥¼ ì‚¬ìš©í•œ pseudo-label ìƒì„±
- **Cross-lingual**: XLM-RoBERTa ê¸°ë°˜ ë‹¤êµ­ì–´ ëª¨ë¸
- **í•„í„°ë§ ì‹œìŠ¤í…œ**: 5ë‹¨ê³„ pseudo-label í•„í„°ë§
- **ì‹¤í—˜ ì¬í˜„ ê°€ëŠ¥**: Config ê¸°ë°˜ ì‹¤í—˜ ê´€ë¦¬
- **í†µí•© ë°ì´í„° í¬ë§·**: JSONL ê¸°ë°˜ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (3ë¶„)

### 1. ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/jaewoosoul/XABSA.git
cd XABSA

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. API í‚¤ ì„¤ì •

**Gemini ì‚¬ìš© (ê¶Œì¥ - ë¬´ë£Œ 60 req/min)**:
```bash
# .env íŒŒì¼ ìƒì„±
echo "GOOGLE_API_KEY=your-api-key-here" > .env
```

**API í‚¤ ë°œê¸‰**: https://ai.google.dev/

<details>
<summary>ë‹¤ë¥¸ LLM ì‚¬ìš©í•˜ê¸° (OpenAI, Claude)</summary>

```bash
# OpenAI
echo "OPENAI_API_KEY=sk-your-key" > .env

# Claude
echo "ANTHROPIC_API_KEY=sk-ant-your-key" > .env
```

**ìƒì„¸ ê°€ì´ë“œ**: [SETUP.md](SETUP.md) ì°¸ì¡°
</details>

### 3. í•œêµ­ì–´ ë°ì´í„° ìƒì„±

```bash
# ëŒ€í™”í˜• ì…ë ¥
python scripts/create_korean_data.py --output data/processed/ko_raw.jsonl

# ë˜ëŠ” CSVì—ì„œ ë¡œë“œ
python scripts/create_korean_data.py \
  --csv your_reviews.csv \
  --text-column review_text \
  --output data/processed/ko_raw.jsonl
```

### 4. Pseudo-label ìƒì„±

```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python scripts/run_full_pipeline.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo.jsonl

# ì†ŒëŸ‰ í…ŒìŠ¤íŠ¸ (10ê°œ)
python scripts/run_full_pipeline.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo.jsonl \
  --max-samples 10

# ë˜ëŠ” ëŒ€í™”í˜• ìŠ¤í¬ë¦½íŠ¸
bash run.sh
```

### 5. ê²°ê³¼ í™•ì¸

```bash
# ìƒì„±ëœ pseudo-label í™•ì¸
cat data/pseudo/ko_pseudo.jsonl | head -1 | jq

# í•„í„°ë§ í†µê³„ í™•ì¸
cat data/pseudo/summary.json | jq
```

**ì˜ˆìƒ ì¶œë ¥**:
```json
{
  "id": "ko_000001",
  "lang": "ko",
  "text": "ë°°ì†¡ì´ ì •ë§ ë¹ ë¥´ê³  í’ˆì§ˆë„ ì¢‹ì•„ìš”!",
  "gold_triplets": [
    {"term": "ë°°ì†¡", "category": "DELIVERY", "polarity": "positive"},
    {"term": "í’ˆì§ˆ", "category": "QUALITY", "polarity": "positive"}
  ],
  "split": "unlabeled"
}
```

---

## ğŸ“š ìƒì„¸ ì‚¬ìš© ê°€ì´ë“œ

**[â†’ Scripts CLI ì‚¬ìš©ë²• ë³´ê¸° (SCRIPTS.md)](SCRIPTS.md)**

ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ì˜ CLI ì˜µì…˜ê³¼ ìƒì„¸í•œ ì‚¬ìš© ì˜ˆì‹œë¥¼ í™•ì¸í•˜ì„¸ìš”:
- ë°ì´í„° ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸ (create_korean_data.py, prepare_data.py ë“±)
- Pseudo-label ìƒì„± (run_full_pipeline.py, run_teacher.py)
- ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (train.py, eval.py)
- ì¼ë°˜ì ì¸ ì›Œí¬í”Œë¡œìš°

---

## ğŸ“Š í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœ

### âœ… Phase 1: ë°ì´í„° & Teacher (ì™„ë£Œ)

- [x] í†µí•© ë°ì´í„° íŒŒì´í”„ë¼ì¸ (JSONL í¬ë§·)
- [x] LLM Teacher êµ¬í˜„ (OpenAI, Claude, Gemini, Mock)
- [x] 5ë‹¨ê³„ Pseudo-label í•„í„°ë§ ì‹œìŠ¤í…œ
- [x] í•œêµ­ì–´/ì˜ì–´ ë°ì´í„° íŒŒì„œ
- [x] ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ë° ë¬¸ì„œí™”

**ìƒì„±ëœ ë°ì´í„° í’ˆì§ˆ**:
- 12ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸: 26ê°œ triplet ìƒì„±
- í•„í„°ë§ í†µê³¼ìœ¨: 100%
- Term ì¶”ì¶œ ì •í™•ë„: âœ… ì›ë¬¸ì—ì„œ ì •í™•íˆ ì¶”ì¶œ
- Category ë¶„ë¥˜: âœ… Taxonomy ì¤€ìˆ˜
- Polarity íŒë‹¨: âœ… ë¬¸ë§¥ ë°˜ì˜

### â³ Phase 2: ëª¨ë¸ & í•™ìŠµ (ì˜ˆì •)

- [ ] XLM-RoBERTa ê¸°ë°˜ Student ëª¨ë¸ êµ¬í˜„
- [ ] Training ëª¨ë“ˆ (Multi-task learning)
- [ ] Evaluation ëª¨ë“ˆ (Triplet F1, ATE F1)
- [ ] Contrastive learning (cross-lingual alignment)

### â³ Phase 3: ì‹¤í—˜ & ë³´ê³ ì„œ (ì˜ˆì •)

- [ ] Baseline ì‹¤í—˜ (EN â†’ KO zero-shot)
- [ ] Pseudo-label íš¨ê³¼ ê²€ì¦
- [ ] Filtering ablation study
- [ ] Few-shot ì‹¤í—˜ (10/50/100 ìƒ˜í”Œ)
- [ ] `report.md` ìë™ ìƒì„±

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
XABSA/
â”œâ”€â”€ configs/                    # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ taxonomy.yaml           # 13ê°œ ì¹´í…Œê³ ë¦¬ ì •ì˜
â”‚   â”œâ”€â”€ teacher.yaml            # LLM Teacher ì„¤ì •
â”‚   â”œâ”€â”€ baseline.yaml           # Baseline ì‹¤í—˜
â”‚   â””â”€â”€ experiments/            # 5ê°€ì§€ ì‹¤í—˜ ì‹œë‚˜ë¦¬ì˜¤
â”‚
â”œâ”€â”€ data/                       # ë°ì´í„° ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ raw/                    # ì›ë³¸ ë°ì´í„° (SemEval, í•œêµ­ì–´)
â”‚   â”œâ”€â”€ processed/              # JSONL í¬ë§·
â”‚   â””â”€â”€ pseudo/                 # Pseudo-labels
â”‚
â”œâ”€â”€ src/                        # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ data/                   # ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ taxonomy.py         # Taxonomy ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ dataset.py          # PyTorch Dataset
â”‚   â”‚   â”œâ”€â”€ semeval_parser.py   # SemEval íŒŒì„œ
â”‚   â”‚   â””â”€â”€ korean_parser.py    # Korean íŒŒì„œ
â”‚   â”‚
â”‚   â”œâ”€â”€ teacher/                # LLM Teacher âœ…
â”‚   â”‚   â”œâ”€â”€ base.py             # Base Teacher
â”‚   â”‚   â”œâ”€â”€ openai_teacher.py   # OpenAI
â”‚   â”‚   â”œâ”€â”€ claude_teacher.py   # Claude
â”‚   â”‚   â”œâ”€â”€ gemini_teacher.py   # Gemini
â”‚   â”‚   â”œâ”€â”€ prompts.py          # Prompts
â”‚   â”‚   â”œâ”€â”€ validator.py        # Validation
â”‚   â”‚   â””â”€â”€ filter.py           # 5ë‹¨ê³„ í•„í„°ë§
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Student Models (ì˜ˆì •)
â”‚   â”œâ”€â”€ training/               # Training (ì˜ˆì •)
â”‚   â””â”€â”€ evaluation/             # Evaluation (ì˜ˆì •)
â”‚
â”œâ”€â”€ scripts/                    # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ create_korean_data.py   # í•œêµ­ì–´ ë°ì´í„° ìƒì„± âœ…
â”‚   â”œâ”€â”€ run_full_pipeline.py    # ì „ì²´ íŒŒì´í”„ë¼ì¸ âœ…
â”‚   â”œâ”€â”€ run_teacher.py          # Pseudo-label ìƒì„± âœ…
â”‚   â”œâ”€â”€ prepare_data.py         # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ train.py                # í•™ìŠµ (ì˜ˆì •)
â”‚   â””â”€â”€ eval.py                 # í‰ê°€ (ì˜ˆì •)
â”‚
â”œâ”€â”€ results/                    # ì‹¤í—˜ ê²°ê³¼
â”œâ”€â”€ logs/                       # ë¡œê·¸
â””â”€â”€ README.md                   # ì´ íŒŒì¼
```

---

## ë°ì´í„° í¬ë§·

### í†µí•© JSONL í¬ë§·

ëª¨ë“  ë°ì´í„°ëŠ” ë‹¤ìŒ í¬ë§·ìœ¼ë¡œ í†µì¼:

```json
{
  "id": "unique_id",
  "lang": "ko",
  "text": "ë°°ì†¡ì€ ë¹ ë¥¸ë° í¬ì¥ì´ ë¶€ì‹¤í–ˆì–´ìš”.",
  "gold_triplets": [
    {"term": "ë°°ì†¡", "category": "DELIVERY", "polarity": "positive"},
    {"term": "í¬ì¥", "category": "PACKAGING", "polarity": "negative"}
  ],
  "split": "train"
}
```

### Category Taxonomy

13ê°œ ë„ë©”ì¸ ì¼ë°˜í˜• ì¹´í…Œê³ ë¦¬:

| Category | ì„¤ëª… | ì˜ˆì‹œ |
|----------|------|------|
| PRICE | ê°€ê²©, ë¹„ìš© | "ê°€ê²©ì´ ì €ë ´í•´ìš”" |
| QUALITY | í’ˆì§ˆ | "í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤" |
| DELIVERY | ë°°ì†¡ | "ë°°ì†¡ì´ ë¹¨ë¼ìš”" |
| SERVICE | ì„œë¹„ìŠ¤ | "ì¹œì ˆí•œ ì‘ëŒ€" |
| DESIGN | ë””ìì¸, ì™¸ê´€ | "ë””ìì¸ì´ ì˜ˆë»ìš”" |
| PERFORMANCE | ì„±ëŠ¥ | "ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤" |
| DURABILITY | ë‚´êµ¬ì„± | "ì˜¤ë˜ ì“¸ ìˆ˜ ìˆì–´ìš”" |
| USABILITY | ì‚¬ìš©ì„± | "ì‚¬ìš©í•˜ê¸° í¸í•´ìš”" |
| PACKAGING | í¬ì¥ | "í¬ì¥ì´ ê¼¼ê¼¼í•´ìš”" |
| SIZE | í¬ê¸° | "í¬ê¸°ê°€ ì ë‹¹í•´ìš”" |
| RETURN | ë°˜í’ˆ/êµí™˜ | "ë°˜í’ˆì´ ì‰¬ì›Œìš”" |
| VALUE | ê°€ì„±ë¹„ | "ê°€ì„±ë¹„ê°€ ì¢‹ì•„ìš”" |
| ETC | ê¸°íƒ€ | - |

ì „ì²´ ì •ì˜: [configs/taxonomy.yaml](configs/taxonomy.yaml)

---

## LLM Teacher

### ì§€ì› ëª¨ë¸

- **OpenAI**: GPT-4, GPT-4 Turbo, GPT-3.5
- **Anthropic**: Claude 3 Opus, Sonnet, Haiku
- **Google**: Gemini 1.5 Pro, Flash (ê¶Œì¥)
- **Mock**: API ì—†ì´ í…ŒìŠ¤íŠ¸ìš©

### 5ë‹¨ê³„ í•„í„°ë§ ì‹œìŠ¤í…œ

1. **Term existence check**: termì´ ì›ë¬¸ì— substringìœ¼ë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
2. **Deduplication**: ì¤‘ë³µ triplet ì œê±° (ê³µë°±/ì¡°ì‚¬ ì •ê·œí™”)
3. **Category validation**: taxonomyì— ì •ì˜ëœ ì¹´í…Œê³ ë¦¬ë§Œ í—ˆìš©
4. **Triplet count limit**: ê³¼ë„í•œ triplet ì œê±° (ê¸°ë³¸: ìµœëŒ€ 8ê°œ)
5. **Self-consistency** (ì˜µì…˜): ë™ì¼ ë¬¸ì¥ 3íšŒ ìƒì„± â†’ í•©ì˜ëœ tripletë§Œ ì±„íƒ

### ì‚¬ìš© ì˜ˆì‹œ

```bash
# Gemini (ê¶Œì¥)
python scripts/run_teacher.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo.jsonl \
  --teacher gemini \
  --filter

# OpenAI GPT-4
python scripts/run_teacher.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo.jsonl \
  --teacher openai \
  --model gpt-4-turbo-preview \
  --filter

# Claude
python scripts/run_teacher.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo.jsonl \
  --teacher claude \
  --filter

# Mock (API ì—†ì´ í…ŒìŠ¤íŠ¸)
python scripts/run_teacher.py \
  --input examples/sample_korean_reviews.csv \
  --output data/pseudo/test.jsonl \
  --teacher mock \
  --max-samples 10
```

---

## ì‹¤í—˜ ì„¤ê³„

í”„ë¡œì íŠ¸ëŠ” 5ê°€ì§€ ì£¼ìš” ì‹¤í—˜ì„ ì§€ì›:

| ì‹¤í—˜ | ì„¤ëª… | Config |
|------|------|--------|
| **Exp1: Baseline** | EN goldë§Œ ì‚¬ìš©, KO zero-shot í‰ê°€ | `exp1_baseline_en.yaml` |
| **Exp2: Pseudo-label** | EN gold + KO pseudo | `exp2_pseudo_added.yaml` |
| **Exp3: Filtering ablation** | í•„í„°ë§ ì „ëµ ë¹„êµ | `exp3_filtering_ablation.yaml` |
| **Exp4: Contrastive** | Cross-lingual alignment | `exp4_contrastive.yaml` |
| **Exp5: Few-shot** | KO gold 10/50/100 ìƒ˜í”Œ ì¶”ê°€ | `exp5_fewshot.yaml` |

**ì‹¤í—˜ ì‹¤í–‰** (ì˜ˆì •):
```bash
python scripts/train.py --config configs/experiments/exp1_baseline_en.yaml
```

---

## ê³ ê¸‰ ì‚¬ìš©ë²•

### SemEval ì˜ì–´ ë°ì´í„° ì¤€ë¹„

```bash
# SemEval ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ
python scripts/download_semeval.py --create-dirs

# ë°ì´í„° íŒŒì‹±
python scripts/prepare_data.py \
  --semeval data/raw/semeval/restaurant \
  --out data/processed
```

### í•„í„°ë§ ì˜µì…˜

```bash
# í•„í„°ë§ ì—†ì´ rawë§Œ ìƒì„±
python scripts/run_full_pipeline.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo_raw.jsonl \
  --no-filter

# Self-consistency ì ìš© (3íšŒ ìƒì„±)
python scripts/run_teacher.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo.jsonl \
  --teacher gemini \
  --filter \
  --self-consistency 3
```

### Config ì»¤ìŠ¤í„°ë§ˆì´ì§•

```yaml
# configs/teacher.yaml
teacher:
  type: "gemini"
  model: "gemini-1.5-flash"
  temperature: 0.0

filtering:
  check_term_existence: true
  remove_duplicates: true
  max_triplets_per_text: 8
  self_consistency_rounds: 0  # 0: ë¹„í™œì„±í™”, 3: 3íšŒ ìƒì„±
```

---

## ë¬¸ì œ í•´ê²°

### "API key not found" ì—ëŸ¬

```bash
# .env íŒŒì¼ í™•ì¸
cat .env

# API í‚¤ ì„¤ì • í™•ì¸
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print('OK' if os.getenv('GOOGLE_API_KEY') else 'NOT FOUND')"
```

### Rate limit ì—ëŸ¬

Gemini ë¬´ë£Œ í‹°ì–´ëŠ” 60 requests/minute ì œí•œì´ ìˆìŠµë‹ˆë‹¤.

```bash
# ì†ŒëŸ‰ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì‹¤í–‰
python scripts/run_full_pipeline.py \
  --input data/processed/ko_raw.jsonl \
  --output data/pseudo/ko_pseudo_part1.jsonl \
  --max-samples 50
```

### ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜

```bash
# ìƒì„¸ ë¡œê·¸ í™•ì¸
python scripts/prepare_data.py \
  --semeval data/raw/semeval/restaurant \
  --log-level DEBUG
```

---

## ê°œë°œ ê°€ì´ë“œ

### ìƒˆë¡œìš´ Parser ì¶”ê°€

```python
from src.data.taxonomy import Taxonomy

class MyParser:
    def __init__(self, taxonomy: Taxonomy):
        self.taxonomy = taxonomy

    def parse(self, input_path: str) -> List[Dict]:
        # Parse and return JSONL format
        pass
```

### ìƒˆë¡œìš´ Teacher ì¶”ê°€

```python
from src.teacher.base import BaseTeacher

class MyTeacher(BaseTeacher):
    def generate_triplets(self, text: str, lang: str) -> List[Dict]:
        # Generate triplets
        pass
```

---

## ê¸°ì—¬í•˜ê¸°

Pull requestsë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! ìì„¸í•œ ë‚´ìš©ì€ [CONTRIBUTING.md](CONTRIBUTING.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ë¼ì´ì„ ìŠ¤

MIT License

---

## Citation

```bibtex
@software{xabsa2024,
  title={XABSA: Cross-lingual Aspect-Based Sentiment Analysis},
  author={Jaewoo Soul},
  year={2024},
  url={https://github.com/jaewoosoul/XABSA}
}
```

---

## ë¬¸ì˜

Issues: https://github.com/jaewoosoul/XABSA/issues
