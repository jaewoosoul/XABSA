#!/usr/bin/env python3
"""
ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

1. ë°ì´í„° í™•ì¸
2. LLM Teacherë¡œ pseudo-label ìƒì„± (Gemini)
3. í•„í„°ë§ ì ìš©
4. í†µê³„ ì¶œë ¥
"""

import argparse
import logging
import sys
from pathlib import Path
import os

# Load .env file
from dotenv import load_dotenv
load_dotenv()

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import load_config
from src.data.taxonomy import Taxonomy
from src.teacher import GeminiTeacher, PseudoLabelFilter
from src.utils import (
    setup_logging, load_jsonl, save_jsonl,
    save_json, ensure_dir
)

logger = logging.getLogger(__name__)


def check_api_key():
    """API í‚¤ í™•ì¸"""
    api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
    if not api_key:
        logger.error(
            "\nâŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\n\n"
            "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:\n"
            "1. .env íŒŒì¼ì— GOOGLE_API_KEY=your-key ì¶”ê°€\n"
            "2. í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •: export GOOGLE_API_KEY=your-key\n\n"
            "API í‚¤ ë°œê¸‰: https://ai.google.dev/\n"
        )
        sys.exit(1)

    logger.info(f"âœ“ API í‚¤ í™•ì¸ ì™„ë£Œ (ê¸¸ì´: {len(api_key)})")
    return api_key


def main():
    parser = argparse.ArgumentParser(
        description="ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Gemini API)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‹¤í–‰ (config íŒŒì¼ ì‚¬ìš©)
  python scripts/run_full_pipeline.py \\
    --input data/processed/ko_raw.jsonl \\
    --output data/pseudo/ko_pseudo.jsonl

  # ì»¤ìŠ¤í…€ ì„¤ì •
  python scripts/run_full_pipeline.py \\
    --input data/processed/ko_raw.jsonl \\
    --output data/pseudo/ko_pseudo.jsonl \\
    --model gemini-1.5-pro \\
    --max-samples 100

  # í•„í„°ë§ ì—†ì´ rawë§Œ ìƒì„±
  python scripts/run_full_pipeline.py \\
    --input data/processed/ko_raw.jsonl \\
    --output data/pseudo/ko_pseudo_raw.jsonl \\
    --no-filter
        """
    )

    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="ì…ë ¥ JSONL íŒŒì¼ (unlabeled í•œêµ­ì–´ ë¦¬ë·°)"
    )

    parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="ì¶œë ¥ JSONL íŒŒì¼ (pseudo-labeled ë°ì´í„°)"
    )

    parser.add_argument(
        "--config",
        type=str,
        default="configs/teacher.yaml",
        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: configs/teacher.yaml)"
    )

    parser.add_argument(
        "--model",
        type=str,
        default="gemini-flash-latest",
        help="Gemini ëª¨ë¸ (ê¸°ë³¸ê°’: gemini-flash-latest)"
    )

    parser.add_argument(
        "--max-samples",
        type=int,
        help="ì²˜ë¦¬í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)"
    )

    parser.add_argument(
        "--no-filter",
        action="store_true",
        help="í•„í„°ë§ ì—†ì´ raw pseudo-labelë§Œ ìƒì„±"
    )

    parser.add_argument(
        "--log-level",
        type=str,
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="ë¡œê·¸ ë ˆë²¨"
    )

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    setup_logging(args.log_level)

    print("\n" + "="*70)
    print("ğŸš€ XABSA Pseudo-Label Generation Pipeline (Gemini)")
    print("="*70 + "\n")

    # Step 1: API í‚¤ í™•ì¸
    logger.info("Step 1: API í‚¤ í™•ì¸...")
    api_key = check_api_key()

    # Step 2: ì„¤ì • ë¡œë“œ
    logger.info(f"Step 2: ì„¤ì • ë¡œë“œ... ({args.config})")
    config = load_config(args.config)

    # Step 3: Taxonomy ë¡œë“œ
    taxonomy_path = config.get("taxonomy_path", "configs/taxonomy.yaml")
    logger.info(f"Step 3: Taxonomy ë¡œë“œ... ({taxonomy_path})")
    taxonomy = Taxonomy(taxonomy_path)
    logger.info(f"  - {len(taxonomy.categories)} ì¹´í…Œê³ ë¦¬: {', '.join(taxonomy.categories[:5])}...")

    # Step 4: ì…ë ¥ ë°ì´í„° ë¡œë“œ
    logger.info(f"Step 4: ì…ë ¥ ë°ì´í„° ë¡œë“œ... ({args.input})")
    if not Path(args.input).exists():
        logger.error(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        logger.info("\në¨¼ì € ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:")
        logger.info("  python scripts/create_korean_data.py --output data/processed/ko_raw.jsonl")
        sys.exit(1)

    samples = load_jsonl(args.input)

    if args.max_samples:
        samples = samples[:args.max_samples]
        logger.info(f"  - {len(samples)}ê°œ ìƒ˜í”Œë¡œ ì œí•œ (--max-samples={args.max_samples})")
    else:
        logger.info(f"  - ì´ {len(samples)}ê°œ ìƒ˜í”Œ")

    # ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°
    if samples:
        logger.info(f"\n  ì²« ë²ˆì§¸ ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°:")
        logger.info(f"  ID: {samples[0]['id']}")
        logger.info(f"  Text: {samples[0]['text'][:100]}...")

    # Step 5: Gemini Teacher ìƒì„±
    logger.info(f"\nStep 5: Gemini Teacher ì´ˆê¸°í™”... (model={args.model})")
    teacher_config = config.get("teacher", {})

    teacher = GeminiTeacher(
        model=args.model,
        api_key=api_key,
        temperature=teacher_config.get("temperature", 0.0),
        max_tokens=teacher_config.get("max_tokens", 1000),
        max_retries=teacher_config.get("max_retries", 3)
    )
    logger.info(f"  - {teacher}")

    # Step 6: Pseudo-label ìƒì„±
    logger.info(f"\nStep 6: Pseudo-label ìƒì„± ì¤‘...")
    logger.info(f"  (Gemini API í˜¸ì¶œ ì¤‘... ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

    from tqdm import tqdm

    pseudo_labeled = []
    errors = 0

    for sample in tqdm(samples, desc="  Generating"):
        try:
            triplets = teacher.generate_triplets(
                sample["text"],
                lang=sample.get("lang", "ko")
            )

            pseudo_sample = sample.copy()
            pseudo_sample["gold_triplets"] = triplets
            pseudo_labeled.append(pseudo_sample)

        except Exception as e:
            logger.debug(f"Error on {sample['id']}: {e}")
            errors += 1
            pseudo_sample = sample.copy()
            pseudo_sample["gold_triplets"] = []
            pseudo_labeled.append(pseudo_sample)

    logger.info(f"  - ìƒì„± ì™„ë£Œ: {len(pseudo_labeled) - errors}ê°œ ì„±ê³µ, {errors}ê°œ ì‹¤íŒ¨")

    # í†µê³„
    total_triplets = sum(len(s["gold_triplets"]) for s in pseudo_labeled)
    avg_triplets = total_triplets / len(pseudo_labeled) if pseudo_labeled else 0
    logger.info(f"  - ì´ {total_triplets}ê°œ triplet ìƒì„± (í‰ê· : {avg_triplets:.2f}ê°œ/ìƒ˜í”Œ)")

    # Step 7: Raw ì €ì¥
    output_path = Path(args.output)
    ensure_dir(output_path.parent)

    raw_output = output_path.parent / f"{output_path.stem}_raw.jsonl"
    save_jsonl(pseudo_labeled, str(raw_output))
    logger.info(f"\nStep 7: Raw pseudo-label ì €ì¥ ì™„ë£Œ")
    logger.info(f"  - {raw_output}")

    # Step 8: í•„í„°ë§ (ì˜µì…˜)
    if not args.no_filter:
        logger.info(f"\nStep 8: í•„í„°ë§ ì ìš© ì¤‘...")

        filter_config = config.get("filtering", {})
        filter_obj = PseudoLabelFilter(
            taxonomy=taxonomy,
            check_term_existence=filter_config.get("check_term_existence", True),
            remove_duplicates=filter_config.get("remove_duplicates", True),
            normalize_whitespace=filter_config.get("normalize_whitespace", True),
            validate_category=filter_config.get("validate_category", True),
            map_to_etc=filter_config.get("map_to_etc", True),
            max_triplets_per_text=filter_config.get("max_triplets_per_text", 8)
        )

        filtered = filter_obj.filter_batch(pseudo_labeled)

        # í•„í„°ë§ í›„ ì €ì¥
        save_jsonl(filtered, str(output_path))
        logger.info(f"  - í•„í„°ë§ ì™„ë£Œ: {args.output}")

        # í†µê³„ ì €ì¥
        stats = filter_obj.get_summary()
        stats_path = output_path.parent / "summary.json"
        save_json(stats, str(stats_path))
        logger.info(f"  - í†µê³„ ì €ì¥: {stats_path}")

        # í†µê³„ ì¶œë ¥
        print("\n" + "="*70)
        print("ğŸ“Š í•„í„°ë§ ê²°ê³¼")
        print("="*70)
        print(f"í•„í„°ë§ ì „: {stats['total_before']} triplets")
        print(f"í•„í„°ë§ í›„: {stats['total_after']} triplets")
        print(f"ì œê±°ë¨:     {stats['removed']} triplets ({100-stats['retention_rate']*100:.1f}%)")
        print(f"ìœ ì§€ìœ¨:     {stats['retention_rate']*100:.1f}%")

        print("\nìƒì„¸ breakdown:")
        for key, value in stats['breakdown'].items():
            print(f"  - {key}: {value}")
    else:
        # í•„í„°ë§ ì—†ì´ ì €ì¥
        save_jsonl(pseudo_labeled, str(output_path))
        logger.info(f"\nStep 8: í•„í„°ë§ ê±´ë„ˆëœ€ (--no-filter)")
        logger.info(f"  - {args.output}")

    # ì™„ë£Œ
    print("\n" + "="*70)
    print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("="*70)
    print(f"\nì¶œë ¥ íŒŒì¼:")
    print(f"  - Raw:      {raw_output}")
    if not args.no_filter:
        print(f"  - Filtered: {output_path}")
        print(f"  - Stats:    {stats_path}")

    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  1. ìƒì„±ëœ ë°ì´í„° í™•ì¸")
    print("  2. ëª¨ë¸ í•™ìŠµ (ì˜ˆì •)")
    print("  3. í‰ê°€ (ì˜ˆì •)")


if __name__ == "__main__":
    main()
